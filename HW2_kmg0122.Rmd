---
title: "Homework 2"
author: "Mingang Kim"
date: '2021 9 9 '
output:
  pdf_document:
    latex_engine: xelatex
header-includes: \usepackage{dcolumn}
---


# 1.

# 2.

### A.
Even though my major in undergrad and master's degree was statistics, I am not confident about my coding skill. Whenever people ask me if I am good at coding, I am not confident. By taking class, I want to improve my programming skill and want to be more confident. 
\begin{enumerate}
\item Learn how to code neatly.
\item Improve visualization skill.
\item Code Latex without looking at cheat sheets.
\end{enumerate}


### B.

\begin{eqnarray}
P(X=x|N)=\frac{1}{N}, x=1,2,3,..,N \\
P(Y=y|n,p)= {{n}\choose{y}} p^{y}(1-p)^{n-y}, y=0,1,2,...,n  \\
P(X=x|r,p)={{x-1}\choose{r-1}}p^{r}(1-p)^{x-r}, x=r,r+1,...,
\end{eqnarray} 


# 3.
\begin{enumerate}
\item Rule 1: For Every Result, Keep Track of How It Was Produced
\begin{itemize}
\item There are many interrelated steps making raw data into the final result. 
\item It is important to record a name and version of the program, as well as the exact parameters and inputs that were used for reproducible research.
\item  Analysis can be reproduced by specifying the full analysis workflow in a form that allows for direct execution.
\item Challenges: How to record the whole steps briefly and exactly in a way that allows perfect sync with its final version.
\end{itemize}


\item Rule 2: Avoid Manual Data Manipulation Steps
\begin{itemize}
\item Avoid relying on manual procedures to modify data because  it is not efficient and easy to make error which makes reproduction difficult. 
\item  If manual operations are inevitable, note down which data files were modified or moved, and the purpose of execution as briefly as you can.
\item Challenges: Before recording manually, how to reproduce the analyses with manual procedures should be considered. 
\end{itemize}

\item Rule 3: Archive the Exact Versions of All External Programs Used
\begin{itemize}
\item  It is important to archive the exact versions of programs to avoid unnecessary hassle.
\item  Codes can only be executed in a specific version of program. 
\item Challenges: It is easy to think that the version is not important and newest version is good. 
\end{itemize}

\item Rule 4: Version Control All Custom Scripts
\begin{itemize}
\item In some cases, it is necessary to track down exact reproduction of results. 
\item Use Subversion, Git, or Mercurial to version control.
\item Challenges: Update the newest version of code on a regular basis and should not forget about version control.
\end{itemize}

\item Rule 5: Record All Intermediate Results, When Possible in Standardized Formats
\begin{itemize}
\item Intermediate results can reveal discrepancies and it will be a good way to uncover bugs or faulty interpretations.
\item It is possible to rerun the parts when the full process is not readily executable. 
\item It is possible to find on which steps problems appears. 
\item Without executing the full process, it is possible to examine the full process. 
\item Challenges: Archive intermediate result files will require a lot of storage.

\end{itemize}

\item Rule 6: For Analyses That Include Randomness, Note Underlying Random Seeds
\begin{itemize}
\item If random seed is not fixed, the same program will give different result every time. 
\item Thus, random seed should be recorded if analysis steps involve randomness. 
\item Challenges: There is no challenge but some codes can be run on specific random seeds. So the analyzer should keep in mind that the analyze can be reproduced in specific condition. 
\end{itemize}


\item Rule 7: Always Store Raw Data behind Plots
\begin{itemize}
\item If the raw data behind figures are stored in a systematic manner, given figures can be easily retrieved. 
\item If one really wants to read fine values in a figure, it is possible to consult the raw numbers.
\item Challenges: Raw data should be saved for backup before using it because data can be modified by mistake. 
\end{itemize}


\item Rule 8: Generate Hierarchical Analysis Output, Allowing Layers of Increasing Detail to Be Inspected
\begin{itemize}
\item It is not practical to incorporate various debug outputs in the source code of scripts and programs.
\item Rather than that, hypertext is useful to inspect the detailed values underlying the summaries.
\item Challenges: Summarizing results to be generated along with links that can be difficult and take a lot of time. 
\end{itemize}

\item Rule 9: Connect Textual Statements to Underlying Results
\begin{itemize}
\item Results and interpretations are located in different area and forms. 
\item Making this connection when it is needed may not be easy and error-prone.
\item To allow efficient retrieval, tools such as Sweave are recommended. 
\item Challenges: Locating the exact result underlying and supporting the statement will not be easy when it comes to a large pool of different analyses with various versions.
\end{itemize}

\item Rule 10: Provide Public Access to Scripts, Runs, and Results
\begin{itemize}
\item All input data, scripts, versions, parameters, and intermediate results should be made publicly and easily accessible for trustworthiness, and transparency.
\item Challenges: Some people will hesitate to share their code and data because they think it is their property and achievement. 
\end{itemize}
\end{enumerate}



# 4.
```{r}
library(data.table)
covid_raw <- fread("https://opendata.ecdc.europa.eu/covid19/casedistribution/csv")
us <- covid_raw[covid_raw$countriesAndTerritories == 'United_States_of_America',]
us_filtered <- us[us$month %in% c(6:7),]
us_filtered$index <- rev(1:dim(us_filtered)[1]) 
fit<-lm(`Cumulative_number_for_14_days_of_COVID-19_cases_per_100000`~index, data=us_filtered)
```
### Part a.

##### 1. 
Create a summary table of the us_filtered data. Hint, use summary and kable in the knitr package. How many time points have we limited ourselves to? Are there missing values?
  
```{r}
library("knitr")
kable(summary(us_filtered), "simple")
summary(is.na(us_filtered))
```

We have 3 time points. Year, Month and day. There is no missing value in the data. 

```{r, results='asis'}
library(stargazer)
stargazer(fit, title="Result",
          single.row = TRUE, type ="latex", header = FALSE)

```


### b.
```{r}
library("broom")
fit.diags <- broom::augment(fit)
fit.diags
```

### 1. residuals vs fitted

```{r}
fitted<-fit.diags$.fitted
residual<-fit.diags$.resid
plot(fitted,residual, xlab="Fitted values", ylab="Residuals", main="Residuals vs Fitted") 
```

### 2. normal Q-Q

```{r}
probs<-seq(0,1,length.out=length(fit.diags$.std.resid))
y<-fit.diags$.std.resid[order(fit.diags$.std.resid)]
norm<-qnorm(probs, lower.tail = TRUE, log.p = FALSE)
plot(norm, y, xlab="Theoritical Qunatiles", ylab="Sample Qunatiles", main = "Normal Q-Q plot")
```

### 3. scale-location

```{r}
fitted<-fit.diags$.fitted
std.r<-fit.diags$.std.resid
sq.std<-sqrt(abs(std.r))
plot(fitted,sq.std, xlab="Fitted values", ylab="sqrt(standarized resiudals)", main="Scale-location") 
```

### 4. residuals vs leverage

```{r}
leverage<-fit.diags$.hat
std.r<-fit.diags$.std.resid
plot(leverage, std.r,  xlab="Leverage", ylab="Resiudals", main="Residuals vs Leverage") 
```

### c. 

Create an auto correlation plot of the residuals using the acf function. The pattern observed is indicative of a time pattern. The simple linear model is not appropriate in this case.

```{r}
acf(fit.diags$.resid)
```


# 5.
```{r}
par(mfrow=c(2,2))
plot(fitted,residual, xlab="Fitted values", ylab="Residuals", main="Residuals vs Fitted")   
plot(norm, y, xlab="Theoritical Qunatiles", ylab="Sample Qunatiles", main = "Normal Q-Q plot")
plot(fitted,sq.std, xlab="Fitted values", ylab="sqrt(standarized resiudals)", main="Scale-location") 
plot(leverage, std.r,  xlab="Leverage", ylab="Resiudals", main="Residuals vs Leverage") 
```